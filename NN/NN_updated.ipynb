{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "#preparing the data : Given a file, the function prepares 2 arrays\n",
    "\"\"\"\n",
    "feature_set : each element is an array of 50 readings\n",
    "one_hot_labels : each element is a label corrisponding to the readings with the same index in feature_set\n",
    "\"\"\"\n",
    "def getSamplesFromFile(fileName=\"mHealth_ECGProcessed_subject3.log\"):\n",
    "    df = pd.read_csv(fileName, header=None, delim_whitespace=True)\n",
    "\n",
    "    one_hot_labels  = np.array([])\n",
    "    feature_set= np.array([])\n",
    "    for i in range(int(df.shape[0]/50)):\n",
    "        if df[2][i*50:i*50+50].mean() in range(1,13):\n",
    "            feature_set=np.append(feature_set,[df[1][i*50:i*50+50]])\n",
    "            one_hot_labels=np.append(one_hot_labels,[[0]*(df[2][i*50]-1)+[1]+[0]*(12-df[2][i*50])])\n",
    "    #     else:\n",
    "    #         print(\"tt: \",i)\n",
    "    feature_set=feature_set.reshape(int(feature_set.shape[0]/50),50)\n",
    "    one_hot_labels=one_hot_labels.reshape(int(one_hot_labels.shape[0]/12),12)\n",
    "    return feature_set, one_hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the NN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # number of hidden nodes in each layer (512)\n",
    "        hidden_1 = 25\n",
    "        # linear layer (784 -> hidden_1)\n",
    "        self.fc1 = nn.Linear(50, hidden_1)\n",
    "        # linear layer (n_hidden -> hidden_2)\n",
    "        self.fc2 = nn.Linear(hidden_1, 12)\n",
    "        # dropout layer (p=0.2)\n",
    "        # dropout prevents overfitting of data\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten image input\n",
    "        x = x.view(-1, 50)\n",
    "        # add hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add hidden layer, with relu activation function\n",
    "        x = self.fc2(x)        \n",
    "        return x\n",
    "\n",
    "# initialize the NN\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set,one_hot_labels=getSamplesFromFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify loss function (categorical cross-entropy)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify optimizer (stochastic gradient descent) and learning rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set=torch.from_numpy(feature_set).float()\n",
    "one_hot_labels=torch.from_numpy(one_hot_labels).long()\n",
    "# number of epochs to train the model\n",
    "n_epochs = 50000000\n",
    "\n",
    "# initialize tracker for minimum validation loss\n",
    "valid_loss_min = np.Inf # set initial \"min\" to infinity\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train() # prep model for training\n",
    "  \n",
    "    # clear the gradients of all optimized variables\n",
    "    optimizer.zero_grad()\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(feature_set)\n",
    "      # calculate the loss\n",
    "    loss = criterion(output, torch.max(one_hot_labels, 1)[1])    \n",
    "    \n",
    "    # backward pass: compute gradient of the loss with respect to model parameters\n",
    "    loss.backward()\n",
    "    # perform a single optimization step (parameter update)\n",
    "    optimizer.step()\n",
    "    \n",
    "   \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} '.format(\n",
    "        epoch+1, \n",
    "        loss.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
